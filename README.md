# perceptron-logical-gates
This project aims to model different logical gates using a simple perceptron algorithm. Perceptron is one of the fundamental building blocks of artificial neural networks, and in this example, it has been utilized to demonstrate how weights are updated to classify inputs correctly.

#How Does it Work?
The project uses a dataset containing inputs and outputs of the AND logical gate. Initially, random weights are assigned, and the perceptron algorithm is used to update these weights. Training iterations continue until all inputs are correctly classified. Eventually, the perceptron finds the correct weights and accurately mimics the AND logical gate.

#Test with Different Logical Gates
You can also test this project with the OR gate. How about giving it a try?
